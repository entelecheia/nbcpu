{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation for Khmer Times\n",
    "\n",
    "## Overview\n",
    "\n",
    "The dataset for Khmer Times is prepared as follows:\n",
    "\n",
    "### 1. Web Scraping\n",
    "\n",
    "Web scraping is performed using Python with the help of the `requests` and `BeautifulSoup` libraries. A Python function is written to crawl the search results pages of the Khmer Times website and extract the URLs of the news articles. The function takes a search keyword as input and iteratively crawls the search results pages until it encounters a page that returns a 404 error, indicating that there are no more results.\n",
    "\n",
    "The structure of the search results pages is as follows:\n",
    "\n",
    "- Each article is contained within an `<article>` tag with the class `item item-media`.\n",
    "- The title of the article is contained within an `<h2>` tag with the class `item-title`.\n",
    "- The URL of the article is contained within an `<a>` tag within the `<h2>` tag.\n",
    "\n",
    "The function extracts the title and URL of each article and stores them in a list of dictionaries.\n",
    "\n",
    "### 2. Article Text Extraction\n",
    "\n",
    "Another Python function is written to follow the URLs extracted in the previous step and scrape the text of the articles. The function iterates over the list of URLs and sends a GET request to each URL. It then parses the HTML of the article page using BeautifulSoup.\n",
    "\n",
    "The structure of the article pages is as follows:\n",
    "\n",
    "- The text of the article is contained within multiple `<p>` tags, which are themselves contained within a `<div>` tag with the class `entry-content`.\n",
    "- The categories of the article are contained within `<a>` tags within a `<div>` tag with the class `entry-meta`.\n",
    "- The publication time of the article is contained within a `<time>` tag within the same `entry-meta` div.\n",
    "\n",
    "The function extracts the text, categories, and publication time of each article and stores them in a list of dictionaries.\n",
    "\n",
    "### 3. Data Serialization\n",
    "\n",
    "The list of dictionaries containing the article data is then serialized to a JSON file using Python's `json` library. The `datetime` objects representing the publication times of the articles are converted to ISO 8601 formatted strings before serialization, as `datetime` objects are not JSON serializable.\n",
    "\n",
    "The resulting JSON file contains an array of objects, where each object represents an article and has a `text`, `categories`, and `time` field. The `text` field contains the text of the article, the `categories` field contains a list of the categories of the article, and the `time` field contains the publication time of the article as an ISO 8601 formatted string.\n",
    "\n",
    "This JSON file serves as the dataset for this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We have saved 40002 articles from Khmer Times. Next task is to do the exploratory data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example snippet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nbcpu\n",
    "%pip install nbcpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yj.lee/.venvs/nbcpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:nbcpu.fetcher.khmer:Fetching links for keyword: NBC\n",
      "INFO:nbcpu.fetcher.khmer:[Keyword: NBC] Page: 1\n",
      "INFO:nbcpu.fetcher.khmer:Title: NBC expanding Bakong operations to more Asian countries\n",
      "INFO:nbcpu.fetcher.khmer:URL: https://www.khmertimeskh.com/501317628/nbc-expanding-bakong-operations-to-more-asian-countries/\n",
      "INFO:nbcpu.fetcher.khmer:[Keyword: NBC] Page: 1\n",
      "INFO:nbcpu.fetcher.khmer:Title: All member banks of the Association of Banks in Cambodia have followed 10% loan portfolio in Riel as mandated by the NBC\n",
      "INFO:nbcpu.fetcher.khmer:URL: https://www.khmertimeskh.com/501265406/all-member-banks-of-the-association-of-banks-in-cambodia-have-followed-10-loan-portfolio-in-riel-as-mandated-by-the-nbc/\n",
      "INFO:nbcpu.fetcher.khmer:[Keyword: NBC] Page: 1\n",
      "INFO:nbcpu.fetcher.khmer:Title: Chea Serey is new NBC Dy Governor\n",
      "INFO:nbcpu.fetcher.khmer:URL: https://www.khmertimeskh.com/501252333/chea-serey-is-new-nbc-dy-governor/\n",
      "INFO:nbcpu.fetcher.khmer:Finished fetching links for keyword: NBC\n",
      "INFO:nbcpu.fetcher.khmer:Total links fetched: 30\n",
      "INFO:nbcpu.fetcher.khmer:Removed 0 duplicate links from 30 links\n",
      "INFO:nbcpu.fetcher.khmer:Saved 30 links to tmp/khmer/links.jsonl\n",
      "INFO:nbcpu.fetcher.khmer:Reached max number of articles, stopping...\n",
      "INFO:nbcpu.fetcher.khmer:Finished scraping articles\n",
      "INFO:nbcpu.fetcher.khmer:Total articles scraped: 5\n",
      "INFO:nbcpu.fetcher.khmer:Removed 0 duplicate articles from 5 articles\n",
      "INFO:nbcpu.fetcher.khmer:Saved 5 articles to tmp/khmer/articles.jsonl\n"
     ]
    }
   ],
   "source": [
    "from nbcpu.fetcher.khmer import KhmerFetcher\n",
    "\n",
    "\n",
    "khmer = KhmerFetcher(\n",
    "    search_keywords=[\"NBC\"],\n",
    "    max_num_pages=1,\n",
    "    max_num_articles=5,\n",
    "    num_workers=1,\n",
    "    output_dir=\"./tmp/khmer\",\n",
    "    overwrite_existing=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "khmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-P5qh1W2b-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
